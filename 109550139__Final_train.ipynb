{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q keras\n","!pip install tensorflow"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672636731701,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"17pnaMbQ2hcg"},"outputs":[],"source":["# Importing libraries\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras.layers as tfl\n","import pandas as pd\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","from copy import deepcopy\n","\n","from sklearn.model_selection import train_test_split\n","import keras"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672636731701,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"ZV7-QnVx2hci"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","from keras.models import load_model\n","from keras import backend as K\n","import csv\n","import cv2\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672636731701,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"bVDK47Iy2hcj"},"outputs":[],"source":["data_train = pd.read_csv('./tabular-playground-series-aug-2022/train.csv')"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672636731702,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"MBQNMSBg2hcj"},"outputs":[],"source":["def clean(data):\n","  \n","  le = LabelEncoder()\n","  \n","  # Replace str by numbers\n","  data = deepcopy(data)\n","  cols = [f\"attribute_{i}\" for i in range(0, 2)] + [\"product_code\"]\n","  for col in cols:\n","      data[col] = le.fit_transform(data[col])\n","      #print(le.classes_)\n","  \n","  data = data.drop(['id', 'product_code'], axis=1)\n","  \n","  # None values\n","  imputer = SimpleImputer(strategy='mean')\n","  final_data = pd.DataFrame(imputer.fit_transform(data))\n","\n","  final_data.columns = data.columns\n","\n","  return final_data\n","  \n","train = clean(data_train)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672636731702,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"9DOjooBu2hcj"},"outputs":[],"source":["X = train.drop('failure', axis=1).to_numpy()\n","Y = train['failure'].astype(np.int32)\n","\n","train_X, val_X, train_y, val_y = train_test_split(X, Y, test_size=0.2, shuffle=False)\n","train_y = train_y.to_numpy()\n","val_y = val_y.to_numpy()\n","\n","val_y = val_y.reshape(val_y.shape[0], 1)\n","train_y = train_y.reshape(train_y.shape[0], 1)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672636731702,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"_LmMMtD42hcj","outputId":"8a53597e-1230-4d20-80f1-205d2914ad0b"},"outputs":[{"data":{"text/plain":["array([101,   1,   2,   9,   5,  13,   2,   6,  17,  11,  18,  18,  12,\n","        19,  12,  16,  18,  10,  15,  15,  16,  17, 826], dtype=int32)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["train_X[3].astype(np.int32)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1672636732067,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"CrevRSF72hcj"},"outputs":[],"source":["inn = Input((23, 1))\n","out = inn\n","out = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(out)\n","out = BatchNormalization()(out)\n","out = MaxPooling1D(pool_size=2)(out)\n","out = Dropout(0.2)(out)\n","out = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(out)\n","out = BatchNormalization()(out)\n","out = MaxPooling1D(pool_size=2)(out)\n","out = Dropout(0.2)(out)\n","out = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(out)\n","out = BatchNormalization()(out)\n","out = MaxPooling1D(pool_size=2)(out)\n","out = Dropout(0.2)(out)\n","out = Conv1D(filters=256, kernel_size=3, padding='same', activation='relu')(out)\n","out = BatchNormalization()(out)\n","out = MaxPooling1D(pool_size=2)(out)\n","out = Flatten()(out)\n","out = Dropout(0.2)(out)\n","# out_shortcut = Dense(units=23, activation='relu', kernel_initializer='he_uniform')(out)\n","# out = Dropout(0.2)(out)\n","# out = Dense(units=32, activation='relu', kernel_initializer='he_uniform')(out)\n","out = Dense(units=1, activation='sigmoid')(out)\n","model = keras.models.Model(inputs=inn, outputs=out)\n","model.compile(optimizer='Adam', loss=tf.keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115136,"status":"ok","timestamp":1672637040271,"user":{"displayName":"楊竺耘","userId":"15022191378567535070"},"user_tz":-480},"id":"xx_RTExS29kV","outputId":"3b6b73c7-6525-4719-fc04-cd453566c7d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\n","Epoch 1: val_accuracy improved from -inf to 0.79281, saving model to ./tabular-playground-series-aug-2022/model.h5\n","333/333 - 3s - loss: 0.5121 - accuracy: 0.7859 - val_loss: 0.5070 - val_accuracy: 0.7928 - 3s/epoch - 8ms/step\n","Epoch 2/50\n","\n","Epoch 2: val_accuracy improved from 0.79281 to 0.79300, saving model to ./tabular-playground-series-aug-2022/model.h5\n","333/333 - 2s - loss: 0.5125 - accuracy: 0.7860 - val_loss: 0.5043 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 3/50\n","\n","Epoch 3: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5119 - accuracy: 0.7858 - val_loss: 0.5037 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 4/50\n","\n","Epoch 4: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5126 - accuracy: 0.7859 - val_loss: 0.5033 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 5/50\n","\n","Epoch 5: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5127 - accuracy: 0.7859 - val_loss: 0.5036 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 6/50\n","\n","Epoch 6: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7863 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 7/50\n","\n","Epoch 7: val_accuracy did not improve from 0.79300\n","333/333 - 3s - loss: 0.5118 - accuracy: 0.7860 - val_loss: 0.5031 - val_accuracy: 0.7928 - 3s/epoch - 10ms/step\n","Epoch 8/50\n","\n","Epoch 8: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5118 - accuracy: 0.7858 - val_loss: 0.5042 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 9/50\n","\n","Epoch 9: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5122 - accuracy: 0.7861 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 10/50\n","\n","Epoch 10: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5112 - accuracy: 0.7859 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 11/50\n","\n","Epoch 11: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5122 - accuracy: 0.7859 - val_loss: 0.5031 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 12/50\n","\n","Epoch 12: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5121 - accuracy: 0.7859 - val_loss: 0.5036 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 13/50\n","\n","Epoch 13: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5111 - accuracy: 0.7858 - val_loss: 0.5036 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 14/50\n","\n","Epoch 14: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5123 - accuracy: 0.7860 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 15/50\n","\n","Epoch 15: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5119 - accuracy: 0.7859 - val_loss: 0.5035 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 16/50\n","\n","Epoch 16: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5118 - accuracy: 0.7859 - val_loss: 0.5034 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 17/50\n","\n","Epoch 17: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5120 - accuracy: 0.7859 - val_loss: 0.5033 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 18/50\n","\n","Epoch 18: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5120 - accuracy: 0.7858 - val_loss: 0.5035 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 19/50\n","\n","Epoch 19: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7860 - val_loss: 0.5089 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 20/50\n","\n","Epoch 20: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5121 - accuracy: 0.7859 - val_loss: 0.5041 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 21/50\n","\n","Epoch 21: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5116 - accuracy: 0.7860 - val_loss: 0.5032 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 22/50\n","\n","Epoch 22: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5117 - accuracy: 0.7859 - val_loss: 0.5031 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 23/50\n","\n","Epoch 23: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5112 - accuracy: 0.7861 - val_loss: 0.5039 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 24/50\n","\n","Epoch 24: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7860 - val_loss: 0.5036 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 25/50\n","\n","Epoch 25: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5110 - accuracy: 0.7858 - val_loss: 0.5040 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 26/50\n","\n","Epoch 26: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5116 - accuracy: 0.7860 - val_loss: 0.5032 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 27/50\n","\n","Epoch 27: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5116 - accuracy: 0.7860 - val_loss: 0.5042 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 28/50\n","\n","Epoch 28: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5111 - accuracy: 0.7858 - val_loss: 0.5036 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 29/50\n","\n","Epoch 29: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5118 - accuracy: 0.7860 - val_loss: 0.5035 - val_accuracy: 0.7926 - 2s/epoch - 7ms/step\n","Epoch 30/50\n","\n","Epoch 30: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5109 - accuracy: 0.7860 - val_loss: 0.5036 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 31/50\n","\n","Epoch 31: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5114 - accuracy: 0.7862 - val_loss: 0.5034 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 32/50\n","\n","Epoch 32: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5112 - accuracy: 0.7859 - val_loss: 0.5047 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 33/50\n","\n","Epoch 33: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7860 - val_loss: 0.5032 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 34/50\n","\n","Epoch 34: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5119 - accuracy: 0.7862 - val_loss: 0.5039 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 35/50\n","\n","Epoch 35: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5112 - accuracy: 0.7860 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 36/50\n","\n","Epoch 36: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5119 - accuracy: 0.7860 - val_loss: 0.5033 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 37/50\n","\n","Epoch 37: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5113 - accuracy: 0.7860 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 38/50\n","\n","Epoch 38: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5116 - accuracy: 0.7859 - val_loss: 0.5049 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 39/50\n","\n","Epoch 39: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5113 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 40/50\n","\n","Epoch 40: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5117 - accuracy: 0.7859 - val_loss: 0.5036 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 41/50\n","\n","Epoch 41: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7861 - val_loss: 0.5042 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 42/50\n","\n","Epoch 42: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5118 - accuracy: 0.7859 - val_loss: 0.5042 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 43/50\n","\n","Epoch 43: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5115 - accuracy: 0.7860 - val_loss: 0.5039 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 44/50\n","\n","Epoch 44: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5111 - accuracy: 0.7860 - val_loss: 0.5085 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 45/50\n","\n","Epoch 45: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5114 - accuracy: 0.7860 - val_loss: 0.5033 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 46/50\n","\n","Epoch 46: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5120 - accuracy: 0.7861 - val_loss: 0.5037 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 47/50\n","\n","Epoch 47: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5108 - accuracy: 0.7858 - val_loss: 0.5034 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 48/50\n","\n","Epoch 48: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5114 - accuracy: 0.7860 - val_loss: 0.5034 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n","Epoch 49/50\n","\n","Epoch 49: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5113 - accuracy: 0.7862 - val_loss: 0.5031 - val_accuracy: 0.7930 - 2s/epoch - 7ms/step\n","Epoch 50/50\n","\n","Epoch 50: val_accuracy did not improve from 0.79300\n","333/333 - 2s - loss: 0.5111 - accuracy: 0.7860 - val_loss: 0.5031 - val_accuracy: 0.7928 - 2s/epoch - 7ms/step\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f740005d1f0>"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["filepath = \"./tabular-playground-series-aug-2022/model.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=70, batch_size=64, callbacks = callbacks_list, verbose=2)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
